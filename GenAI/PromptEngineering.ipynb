{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV78FJjw3qE/U8UM5x6KOE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41a9dd32717e4b3cadeda9d9d42eeefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd2557e32dcd438bb2c4e666110424b8",
              "IPY_MODEL_9f5ae436ee274a2ba846726291723159",
              "IPY_MODEL_fd7c75ccf0344dada04afdf62ae7d3c8"
            ],
            "layout": "IPY_MODEL_ab6f7b0f8405446ca319278cf921c931"
          }
        },
        "fd2557e32dcd438bb2c4e666110424b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c1ba3916e0419e84b8f5bdf4602701",
            "placeholder": "​",
            "style": "IPY_MODEL_86d2519c1c6449a39bad98a3dd7c32ca",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "9f5ae436ee274a2ba846726291723159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df6d4e8cae8c4efba1e87d65a3e1c182",
            "max": 17719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5af181d12c534b4e86b99f31e95438db",
            "value": 17719
          }
        },
        "fd7c75ccf0344dada04afdf62ae7d3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47c4a207fc0f40e28b48f250dee3f078",
            "placeholder": "​",
            "style": "IPY_MODEL_e7269c41888a4cb08476481bdb0697a7",
            "value": " 17.7k/17.7k [00:00&lt;00:00, 625kB/s]"
          }
        },
        "ab6f7b0f8405446ca319278cf921c931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7c1ba3916e0419e84b8f5bdf4602701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d2519c1c6449a39bad98a3dd7c32ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df6d4e8cae8c4efba1e87d65a3e1c182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af181d12c534b4e86b99f31e95438db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47c4a207fc0f40e28b48f250dee3f078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7269c41888a4cb08476481bdb0697a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "301993678e774f6980ba376cf0563b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_993c6a47cc284f5ebcba7b827afa65b2",
              "IPY_MODEL_8aa33e58e4244a459d9c3c93e5364ce3",
              "IPY_MODEL_16aa00e5dd6f48ecb52ccad1c5222df0"
            ],
            "layout": "IPY_MODEL_72ba0380fa8448708f6776a449f0d6c1"
          }
        },
        "993c6a47cc284f5ebcba7b827afa65b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6404111573d640298b9efaadd5eae7ab",
            "placeholder": "​",
            "style": "IPY_MODEL_f06d1110061b4e6cbe4fbaeabf1aed95",
            "value": "Downloading shards:   0%"
          }
        },
        "8aa33e58e4244a459d9c3c93e5364ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd941706a6c4c95b289088f32589c70",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_152751db93354d0ab16d42448ae717b3",
            "value": 0
          }
        },
        "16aa00e5dd6f48ecb52ccad1c5222df0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff84835026fa410780b1c5a917c6e7e8",
            "placeholder": "​",
            "style": "IPY_MODEL_6db05de8a4c74b78b782fa0c2ab16df8",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "72ba0380fa8448708f6776a449f0d6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6404111573d640298b9efaadd5eae7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06d1110061b4e6cbe4fbaeabf1aed95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dd941706a6c4c95b289088f32589c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152751db93354d0ab16d42448ae717b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff84835026fa410780b1c5a917c6e7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db05de8a4c74b78b782fa0c2ab16df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a76991318bb44669f88b3e07c8e59a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9f508c2985341c2b9b5eb342ebaa2d5",
              "IPY_MODEL_1ef6d815667e463cb814a17ff7def0ba",
              "IPY_MODEL_549daf50a6d34c0093b202e2a7f6c2eb"
            ],
            "layout": "IPY_MODEL_f36ea10b7feb45109b3d09783b7e066f"
          }
        },
        "d9f508c2985341c2b9b5eb342ebaa2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d1801ff171e47d1bf68bfeadce8bb75",
            "placeholder": "​",
            "style": "IPY_MODEL_8e82c0a623f549c09465e94e566f73ea",
            "value": "model-00001-of-00002.safetensors:  39%"
          }
        },
        "1ef6d815667e463cb814a17ff7def0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3a25e57c33478a81b7c5cf68dadf01",
            "max": 9950994832,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b090ae9556ea4126a1c0e3d3cfb713d9",
            "value": 3869245440
          }
        },
        "549daf50a6d34c0093b202e2a7f6c2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81c7665b7d540a0a4c5e5ac05f7eb28",
            "placeholder": "​",
            "style": "IPY_MODEL_75f864a35ba24b6aa4a668d2bd4944eb",
            "value": " 3.87G/9.95G [00:45&lt;00:36, 168MB/s]"
          }
        },
        "f36ea10b7feb45109b3d09783b7e066f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1801ff171e47d1bf68bfeadce8bb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e82c0a623f549c09465e94e566f73ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3a25e57c33478a81b7c5cf68dadf01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b090ae9556ea4126a1c0e3d3cfb713d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b81c7665b7d540a0a4c5e5ac05f7eb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f864a35ba24b6aa4a668d2bd4944eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calmrocks/master-machine-learning-engineer/blob/main/GenAI/PromptEngineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Prompt Engineering with Falcon-7B\n",
        "This notebook demonstrates various prompt engineering techniques using the Falcon-7B model. We'll explore different prompting strategies and parameter tuning."
      ],
      "metadata": {
        "id": "bPsHOzw3CRvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practices\n",
        "Key takeaways:\n",
        "1. Zero-shot works best for simple, straightforward tasks\n",
        "2. Chain of Thought is excellent for complex reasoning\n",
        "3. Few-shot is ideal when you have specific examples\n",
        "4. Tree of Thoughts helps with decision-making tasks\n",
        "\n",
        "Best practices:\n",
        "- Start simple and increase complexity as needed\n",
        "- Match the technique to the task type\n",
        "- Consider computational efficiency\n",
        "- Test different temperature values for optimal results"
      ],
      "metadata": {
        "id": "qSdYekyEGJKq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9Lg8erBnAr5e"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import time\n",
        "import gc\n",
        "\n",
        "# Memory management utilities\n",
        "def clear_gpu_memory():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"GPU memory cleared\")\n",
        "\n",
        "def check_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"Used: {torch.cuda.memory_allocated()/1e9:.2f}GB\")\n",
        "        print(f\"Cached: {torch.cuda.memory_reserved()/1e9:.2f}GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Setup\n",
        "We'll use Falcon-7B-Instruct, a powerful 7B parameter model fine-tuned for instruction following. To run it on Colab's T4 GPU (16GB VRAM), we'll use 4-bit quantization to reduce memory usage."
      ],
      "metadata": {
        "id": "BHXqh0QACd_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_model(temperature=0.7, top_p=0.9):\n",
        "    model_id = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "    print(\"Loading Falcon-7B model...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        torch_dtype=torch.float16  # Using float16 instead of 4-bit quantization\n",
        "    )\n",
        "\n",
        "    generator = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=256,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "\n",
        "    return generator\n",
        "\n",
        "# Initialize model once\n",
        "try:\n",
        "    print(\"Checking GPU...\")\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "    global_generator = setup_model()\n",
        "    check_gpu_memory()\n",
        "except Exception as e:\n",
        "    print(f\"Error during setup: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "41a9dd32717e4b3cadeda9d9d42eeefe",
            "fd2557e32dcd438bb2c4e666110424b8",
            "9f5ae436ee274a2ba846726291723159",
            "fd7c75ccf0344dada04afdf62ae7d3c8",
            "ab6f7b0f8405446ca319278cf921c931",
            "d7c1ba3916e0419e84b8f5bdf4602701",
            "86d2519c1c6449a39bad98a3dd7c32ca",
            "df6d4e8cae8c4efba1e87d65a3e1c182",
            "5af181d12c534b4e86b99f31e95438db",
            "47c4a207fc0f40e28b48f250dee3f078",
            "e7269c41888a4cb08476481bdb0697a7",
            "301993678e774f6980ba376cf0563b76",
            "993c6a47cc284f5ebcba7b827afa65b2",
            "8aa33e58e4244a459d9c3c93e5364ce3",
            "16aa00e5dd6f48ecb52ccad1c5222df0",
            "72ba0380fa8448708f6776a449f0d6c1",
            "6404111573d640298b9efaadd5eae7ab",
            "f06d1110061b4e6cbe4fbaeabf1aed95",
            "8dd941706a6c4c95b289088f32589c70",
            "152751db93354d0ab16d42448ae717b3",
            "ff84835026fa410780b1c5a917c6e7e8",
            "6db05de8a4c74b78b782fa0c2ab16df8",
            "0a76991318bb44669f88b3e07c8e59a6",
            "d9f508c2985341c2b9b5eb342ebaa2d5",
            "1ef6d815667e463cb814a17ff7def0ba",
            "549daf50a6d34c0093b202e2a7f6c2eb",
            "f36ea10b7feb45109b3d09783b7e066f",
            "7d1801ff171e47d1bf68bfeadce8bb75",
            "8e82c0a623f549c09465e94e566f73ea",
            "5a3a25e57c33478a81b7c5cf68dadf01",
            "b090ae9556ea4126a1c0e3d3cfb713d9",
            "b81c7665b7d540a0a4c5e5ac05f7eb28",
            "75f864a35ba24b6aa4a668d2bd4944eb"
          ]
        },
        "id": "z59VbPD2BOJD",
        "outputId": "462a9a80-54ac-4352-fec9-271363d92ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking GPU...\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Loading Falcon-7B model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41a9dd32717e4b3cadeda9d9d42eeefe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "301993678e774f6980ba376cf0563b76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a76991318bb44669f88b3e07c8e59a6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation Parameters\n",
        "Let's explore how different parameters affect the model's output:\n",
        "- Temperature: Controls randomness (higher = more creative, lower = more focused)\n",
        "- Top-p: Controls diversity via nucleus sampling\n",
        "- Max tokens: Controls response length"
      ],
      "metadata": {
        "id": "1o7jcaNRHME6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, temperature=0.7, top_p=0.9, max_tokens=256):\n",
        "    try:\n",
        "        response = global_generator(\n",
        "            prompt,\n",
        "            max_new_tokens=max_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p\n",
        "        )\n",
        "        return response[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        return f\"Error generating text: {e}\"\n",
        "\n",
        "# Test generation with different temperatures\n",
        "prompt = \"Write a short story about a robot learning to paint:\"\n",
        "\n",
        "print(\"Testing different temperatures:\")\n",
        "temperatures = [0.3, 0.7, 1.2]\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\nTemperature = {temp}:\")\n",
        "    print(\"-\" * 50)\n",
        "    response = generate_text(prompt, temperature=temp)\n",
        "    print(response)\n",
        "    time.sleep(1)  # Add small delay between generations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "tt0jtpcoHM-_",
        "outputId": "2c0ae4bb-301c-430f-eb0f-b77255200dcd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conservative (Temperature = 0.3):\n",
            "Loading Falcon-7B model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-aa4ebd776bae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Conservative (Temperature = 0.3):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBalanced (Temperature = 0.7):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-aa4ebd776bae>\u001b[0m in \u001b[0;36mgenerate_with_params\u001b[0;34m(prompt, temperature, top_p, max_tokens)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_with_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     response = generator(\n\u001b[1;32m      5\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-0878cd7b60d7>\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(temperature, top_p)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading Falcon-7B model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_generation_mixin_to_remote_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    560\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3620\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3621\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m                 \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m             )\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n",
            "\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Zero-shot Prompting\n",
        "Zero-shot prompting is the simplest form of prompting where we directly ask the model to perform a task without providing any examples. This technique tests the model's ability to understand and perform tasks based solely on instructions.\n",
        "\n",
        "Key characteristics:\n",
        "- No examples provided\n",
        "- Relies on model's pre-trained knowledge\n",
        "- Simplest to implement but may not always give optimal results"
      ],
      "metadata": {
        "id": "YMMrEIacEq5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Zero-shot Prompting Example\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "zero_shot_prompt = \"\"\"Classify the sentiment of this text as positive, negative, or neutral:\n",
        "Text: \"I absolutely love this new phone! It's amazing!\"\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "response = generate_response(generator, zero_shot_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2wS28xmBpd3",
        "outputId": "fc852167-bf2c-44a0-c8ff-470d8b85da52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot Prompting Example\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classify the sentiment of this text as positive, negative, or neutral:\n",
            "Text: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: \"I absolutely love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. One-shot Prompting\n",
        "One-shot prompting provides the model with a single example of the desired task before asking it to perform a similar task. This can help the model better understand the expected format and type of response.\n",
        "\n",
        "Benefits:\n",
        "- Provides context through a single example\n",
        "- Better performance than zero-shot\n",
        "- Still maintains simplicity"
      ],
      "metadata": {
        "id": "sEAITWkeFwun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"One-shot Prompting Example\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "one_shot_prompt = \"\"\"Classify the sentiment of text as positive, negative, or neutral:\n",
        "\n",
        "Text: \"This movie was terrible, I hated it.\"\n",
        "Sentiment: negative\n",
        "\n",
        "Text: \"I absolutely love this new phone! It's amazing!\"\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "response = generate_response(generator, one_shot_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pTPuI-TE2MD",
        "outputId": "afadbe51-6aee-498a-e35d-6c0bc6a6f5c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-shot Prompting Example\n",
            "--------------------------------------------------\n",
            "Classify the sentiment of text as positive, negative, or neutral:\n",
            "\n",
            "Text: \"This movie was terrible, I hated it.\"\n",
            "Sentiment: negative\n",
            "\n",
            "Text: \"I absolutely love this new phone! It's amazing!\"\n",
            "Sentiment: positive\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: neutral\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: positive\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: neutral\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: positive\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: neutral\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: neutral\n",
            "\n",
            "Text: \"I love this movie, it's so funny!\"\n",
            "Sentiment: neutral\n",
            "\n",
            "Text: \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Few-shot Prompting\n",
        "Few-shot prompting extends one-shot prompting by providing multiple examples. This technique helps the model better understand patterns and expectations through multiple demonstrations.\n",
        "\n",
        "Advantages:\n",
        "- More robust performance\n",
        "- Better pattern recognition\n",
        "- Clearer context for complex tasks"
      ],
      "metadata": {
        "id": "XUarnlxfF3m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Few-shot Prompting\n",
        "print(\"Few-shot Prompting Example\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "few_shot_prompt = \"\"\"Solve the following math problems:\n",
        "\n",
        "Problem: What is 15% of 200?\n",
        "Solution: Let's solve this step by step:\n",
        "1. To find 15% of 200, multiply 200 by 15/100\n",
        "2. 200 × 15/100 = 200 × 0.15 = 30\n",
        "Answer: 30\n",
        "\n",
        "Problem: What is 25% of 80?\n",
        "Solution: Let's solve this step by step:\"\"\"\n",
        "\n",
        "response = generate_response(generator, few_shot_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "vWf4oFIBFT_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Chain of Thought (CoT) Prompting\n",
        "print(\"Chain of Thought Example\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "cot_prompt = \"\"\"Let's solve this word problem step by step:\n",
        "\n",
        "Problem: If a store has 150 apples and sells 30% of them on Monday, then sells 40% of the remaining apples on Tuesday, how many apples are left?\n",
        "\n",
        "Let's think about this step by step:\n",
        "1. First, let's calculate how many apples are sold on Monday\n",
        "   * 30% of 150 = 150 × 0.30 = 45 apples sold\n",
        "   * Remaining after Monday = 150 - 45 = 105 apples\n",
        "\n",
        "2. Next, let's calculate Tuesday's sales\n",
        "   * 40% of 105 = 105 × 0.40 = 42 apples sold\n",
        "   * Remaining after Tuesday = 105 - 42 = 63 apples\n",
        "\n",
        "Therefore, there are 63 apples left.\n",
        "\n",
        "Problem: A restaurant has 200 customers per day and 15% are breakfast customers, 45% are lunch customers, and the rest are dinner customers. How many dinner customers are there?\n",
        "\n",
        "Let's think about this step by step:\"\"\"\n",
        "\n",
        "response = generate_response(generator, cot_prompt, max_length=400)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "VaSolv57FWCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: RAG (Retrieval-Augmented Generation) Example\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "# Setup knowledge base\n",
        "knowledge_base = \"\"\"\n",
        "Python is a high-level, interpreted programming language created by Guido van Rossum in 1991.\n",
        "Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming.\n",
        "Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize ChromaDB and embed knowledge\n",
        "chroma_client = chromadb.Client()\n",
        "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction()\n",
        "\n",
        "# Create collection\n",
        "collection = chroma_client.create_collection(\n",
        "    name=\"python_facts\",\n",
        "    embedding_function=sentence_transformer_ef\n",
        ")\n",
        "\n",
        "# Add documents\n",
        "collection.add(\n",
        "    documents=[knowledge_base],\n",
        "    metadatas=[{\"source\": \"python_docs\"}],\n",
        "    ids=[\"doc1\"]\n",
        ")\n",
        "\n",
        "def rag_response(query, collection, generator):\n",
        "    # Retrieve relevant information\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=1\n",
        "    )\n",
        "\n",
        "    # Construct prompt with retrieved information\n",
        "    context = results['documents'][0][0]\n",
        "    prompt = f\"\"\"Using the following information, answer the question.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    return generate_response(generator, prompt)\n",
        "\n",
        "# Example usage\n",
        "query = \"What is Python and who created it?\"\n",
        "response = rag_response(query, collection, generator)\n",
        "print(\"RAG Example\")\n",
        "print(\"-\" * 50)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "WemdtXTGFbZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Instruction-Oriented Prompting (IoT)\n",
        "print(\"Instruction-Oriented Prompting Example\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "iot_prompt = \"\"\"Instructions: Generate a professional email to reschedule a meeting. Use these guidelines:\n",
        "- Be polite and professional\n",
        "- Provide a reason for rescheduling\n",
        "- Suggest two alternative times\n",
        "- Ask for confirmation\n",
        "\n",
        "Email:\"\"\"\n",
        "\n",
        "response = generate_response(generator, iot_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "A6ca7EDMFegt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Tree of Thoughts (ToT) Prompting\n",
        "print(\"Tree of Thoughts Example\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "tot_prompt = \"\"\"Problem: Plan a birthday party for a 10-year-old child.\n",
        "\n",
        "Let's explore multiple thought paths:\n",
        "\n",
        "Path 1 - Indoor Party:\n",
        "1. Venue options:\n",
        "   * Home party\n",
        "   * Indoor playground\n",
        "   * Party center\n",
        "2. Activities:\n",
        "   * Games\n",
        "   * Crafts\n",
        "   * Entertainment\n",
        "\n",
        "Path 2 - Outdoor Party:\n",
        "1. Venue options:\n",
        "   * Park\n",
        "   * Backyard\n",
        "   * Sports facility\n",
        "2. Activities:\n",
        "   * Sports\n",
        "   * Outdoor games\n",
        "   * Nature activities\n",
        "\n",
        "Let's evaluate each path and choose the best option considering:\n",
        "1. Weather risks\n",
        "2. Cost\n",
        "3. Entertainment value\n",
        "4. Practicality\n",
        "\n",
        "Analysis:\"\"\"\n",
        "\n",
        "response = generate_response(generator, tot_prompt, max_length=500)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "pLEb5_CpFjKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}