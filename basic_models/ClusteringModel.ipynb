{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "title": "Customer Segmentation Using Clustering Models"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Case Study: Customer Segmentation Using Clustering Models\n\nIn this case study, we demonstrate the application of clustering models for customer segmentation using the **Mall Customers Dataset**. This dataset contains information about customers' spending habits and demographic details, making it ideal for grouping customers into meaningful segments for targeted marketing."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Dataset Overview\n\nThe **Mall Customers Dataset** is publicly available and contains 200 rows with the following attributes:\n- **CustomerID**: A unique identifier for each customer.\n- **Gender**: The gender of the customer.\n- **Age**: The age of the customer.\n- **Annual Income (k$)**: The annual income of the customer in thousands of dollars.\n- **Spending Score (1-100)**: A score assigned by the mall based on the customer's spending behavior and loyalty.\n\nThe dataset can be downloaded from [Kaggle](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python)."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 1: Data Preparation\n\nBefore applying clustering algorithms, we need to clean and preprocess the data."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the dataset\ndata = pd.read_csv(\"Mall_Customers.csv\")\n\n# Select relevant features for clustering\nfeatures = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n\n# Standardize the features\nscaler = StandardScaler()\nscaled_features = scaler.fit_transform(features)\n\n# Convert to DataFrame for better readability\nscaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n\n# Display the first few rows of the scaled data\nprint(scaled_features_df.head())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Observations:\n- Standardization ensures that all features contribute equally to the clustering process.\n- Features like \"Age\" and \"Annual Income\" have been scaled to remove any bias due to different ranges."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 2: Exploratory Data Analysis\n\n### Visualizing the Data\nBefore clustering, we visualize the relationships between features."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import seaborn as sns\n\n# Pairplot to visualize relationships between features\nsns.pairplot(data, vars=['Age', 'Annual Income (k$)', 'Spending Score (1-100)'], hue='Gender')\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Insights:\n- Spending Score and Annual Income appear to have a non-linear relationship.\n- Gender does not show clear separations, suggesting it may not be a strong feature for clustering."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 3: Model Building\n\n### A. K-Means Clustering\n\nK-Means is a widely used algorithm for grouping customers based on their similarity."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Determine the optimal number of clusters using the Elbow Method\ninertia = []\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(scaled_features)\n    inertia.append(kmeans.inertia_)\n\n# Plot the Elbow Curve\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, 11), inertia, marker='o')\nplt.title(\"Elbow Method\")\nplt.xlabel(\"Number of Clusters\")\nplt.ylabel(\"Inertia\")\nplt.show()\n\n# Fit K-Means with the optimal number of clusters (e.g., 5 from the elbow curve)\nkmeans = KMeans(n_clusters=5, random_state=42)\nkmeans.fit(scaled_features)\nlabels = kmeans.labels_\n\n# Add cluster labels to the dataset\ndata['Cluster'] = labels"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "#### Visualizing Clusters"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Visualize clusters in a 2D space using two features\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=data['Annual Income (k$)'], y=data['Spending Score (1-100)'], hue=data['Cluster'], palette='Set1')\nplt.title(\"Customer Segments\")\nplt.xlabel(\"Annual Income (k$)\")\nplt.ylabel(\"Spending Score (1-100)\")\nplt.legend()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Results:\n- The Elbow Method suggested 5 clusters as the optimal number.\n- Customers were grouped into distinct segments based on their spending behavior and income levels."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### B. DBSCAN for Anomaly Detection\n\nDBSCAN identifies clusters of arbitrary shapes and flags outliers, making it a valuable alternative to K-Means."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "from sklearn.cluster import DBSCAN\n\n# Fit DBSCAN with tuned parameters\ndbscan = DBSCAN(eps=0.5, min_samples=5)\ndbscan.fit(scaled_features)\ndbscan_labels = dbscan.labels_\n\n# Add DBSCAN labels to the dataset\ndata['DBSCAN_Cluster'] = dbscan_labels\n\n# Count the number of outliers\noutliers = (dbscan_labels == -1).sum()\nprint(f\"Number of outliers detected: {outliers}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Results:\n- DBSCAN identified clusters with complex shapes and flagged several outliers.\n- Outliers represent customers with unusual spending or income patterns, which may require special attention."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 4: Cluster Evaluation\n\n### Silhouette Score\nThe silhouette score evaluates the quality of clustering by measuring the separation and cohesion of clusters."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# Calculate Silhouette Score for K-Means\nkmeans_silhouette = silhouette_score(scaled_features, labels)\nprint(f\"K-Means Silhouette Score: {kmeans_silhouette}\")\n\n# Calculate Silhouette Score for DBSCAN\ndbscan_silhouette = silhouette_score(scaled_features, dbscan_labels[dbscan_labels != -1])\nprint(f\"DBSCAN Silhouette Score (excluding outliers): {dbscan_silhouette}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Insights:\n- **K-Means Silhouette Score**: High score indicates well-defined clusters.\n- **DBSCAN Silhouette Score**: Slightly lower score due to the presence of noise and irregular clusters."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 5: Summary and Recommendations\n\n### Summary:\n- **K-Means Clustering**: Identified 5 customer segments based on spending and income patterns. Works well for spherical clusters but is sensitive to outliers.\n- **DBSCAN**: Detected non-spherical clusters and flagged outliers, providing additional insights into unusual customer behaviors.\n\n### Recommendations:\n- Use **K-Means** for general customer segmentation tasks where clusters are expected to be distinct and well-separated.\n- Leverage **DBSCAN** to detect anomalies or when dealing with irregularly shaped clusters.\n- Combine clustering results with domain knowledge to tailor marketing strategies for each customer segment.\n\n### Next Steps:\n- Experiment with advanced clustering techniques like Gaussian Mixture Models or hierarchical clustering for deeper insights.\n- Apply dimensionality reduction techniques, such as PCA or UMAP, to visualize clusters in high-dimensional datasets."
    }
  ]
}
