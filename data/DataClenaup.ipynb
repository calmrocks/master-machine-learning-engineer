{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calmrocks/master-machine-learning-engineer/blob/main/data/DataClenaup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Data Cleaning Techniques\n",
        "\n",
        "1. **Handling Missing Values**\n",
        "    - **Dropping missing values**: If a feature or record has too many missing values, it may be best to remove it entirely. However, this approach may lead to a loss of valuable data if used extensively.\n",
        "    - **Imputing missing values**: For numerical features, you can replace missing values with the mean, median, or mode. For categorical features, the most common value or a placeholder (e.g., \"unknown\") may be used.\n",
        "    - **Predictive imputation**: For more sophisticated handling, use machine learning models to predict missing values based on other features. Techniques such as k-nearest neighbors (KNN) imputation can fill in missing data using similar observations.\n",
        "\n",
        "2. **Outlier Detection and Removal**\n",
        "    - **Statistical methods**: Use the interquartile range (IQR) or Z-score method to identify outliers. Outliers that fall below or above a certain threshold can be removed or capped.\n",
        "    - **Domain knowledge**: Sometimes, outliers may actually represent valid data points. Consult domain experts to determine whether outliers should be removed or retained.\n",
        "    - **Winsorizing**: Replace extreme values with values closer to the mean or median to reduce the effect of outliers without removing data points.\n",
        "\n",
        "3. **Removing Duplicates**\n",
        "    - Duplicate records can skew the distribution of data and lead to biased model outcomes. Use duplicate detection techniques to identify and remove duplicate entries, especially in transactional data where repeated records are common.\n",
        "\n",
        "4. **Standardizing Formats**\n",
        "    - **Text standardization**: For textual data, convert all text to lowercase, remove special characters, and standardize abbreviations (e.g., “N.Y.” to “New York”).\n",
        "    - **Date and time formatting**: Convert date and time information to a standardized format (e.g., `YYYY-MM-DD`) to make it easier to work with time-series data.\n",
        "    - **Categorical standardization**: Standardize categories to ensure consistency across records (e.g., “M” and “Male” both converted to “Male”).\n",
        "\n",
        "5. **Handling Inconsistent Data Entries**\n",
        "    - Inconsistent data entries, such as different spellings or formats for the same value, can lead to errors during analysis. For instance, entries like “CA,” “California,” and “Calif” should be standardized to one consistent format.\n",
        "\n",
        "6. **Removing Irrelevant Features**\n",
        "    - Some features may not add value to the analysis and can be removed. Use domain knowledge or correlation analysis to identify irrelevant or redundant features.\n"
      ],
      "metadata": {
        "id": "XtZjy_qjBCiK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9ETSVuMAbB2"
      },
      "outputs": [],
      "source": []
    }
  ]
}