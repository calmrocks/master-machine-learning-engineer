{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calmrocks/master-machine-learning-engineer/blob/main/data/DataClenaup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common Data Cleaning Techniques\n",
        "\n",
        "1. **Handling Missing Values**\n",
        "    - **Dropping missing values**: If a feature or record has too many missing values, it may be best to remove it entirely. However, this approach may lead to a loss of valuable data if used extensively.\n",
        "    - **Imputing missing values**: For numerical features, you can replace missing values with the mean, median, or mode. For categorical features, the most common value or a placeholder (e.g., \"unknown\") may be used.\n",
        "    - **Predictive imputation**: For more sophisticated handling, use machine learning models to predict missing values based on other features. Techniques such as k-nearest neighbors (KNN) imputation can fill in missing data using similar observations.\n",
        "\n",
        "2. **Outlier Detection and Removal**\n",
        "    - **Statistical methods**: Use the interquartile range (IQR) or Z-score method to identify outliers. Outliers that fall below or above a certain threshold can be removed or capped.\n",
        "    - **Domain knowledge**: Sometimes, outliers may actually represent valid data points. Consult domain experts to determine whether outliers should be removed or retained.\n",
        "    - **Winsorizing**: Replace extreme values with values closer to the mean or median to reduce the effect of outliers without removing data points.\n",
        "\n",
        "3. **Removing Duplicates**\n",
        "    - Duplicate records can skew the distribution of data and lead to biased model outcomes. Use duplicate detection techniques to identify and remove duplicate entries, especially in transactional data where repeated records are common.\n",
        "\n",
        "4. **Standardizing Formats**\n",
        "    - **Text standardization**: For textual data, convert all text to lowercase, remove special characters, and standardize abbreviations (e.g., “N.Y.” to “New York”).\n",
        "    - **Date and time formatting**: Convert date and time information to a standardized format (e.g., `YYYY-MM-DD`) to make it easier to work with time-series data.\n",
        "    - **Categorical standardization**: Standardize categories to ensure consistency across records (e.g., “M” and “Male” both converted to “Male”).\n",
        "\n",
        "5. **Handling Inconsistent Data Entries**\n",
        "    - Inconsistent data entries, such as different spellings or formats for the same value, can lead to errors during analysis. For instance, entries like “CA,” “California,” and “Calif” should be standardized to one consistent format.\n",
        "\n",
        "6. **Removing Irrelevant Features**\n",
        "    - Some features may not add value to the analysis and can be removed. Use domain knowledge or correlation analysis to identify irrelevant or redundant features.\n"
      ],
      "metadata": {
        "id": "XtZjy_qjBCiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the Titanic Dataset for Data Cleaning\n",
        "\n",
        "The **Titanic dataset** contains information about passengers on the Titanic, including details like age, gender, ticket class, and whether they survived. This dataset includes various data issues such as missing values, categorical variables, outliers, and inconsistent entries, allowing us to demonstrate all data cleaning techniques effectively.\n",
        "\n",
        "#### Why the Titanic Dataset?\n",
        "\n",
        "- **Variety of Issues**: The Titanic dataset includes missing values, outliers, categorical variables, and irrelevant features.\n",
        "- **Real-World Relevance**: Its mix of numerical and categorical data reflects typical real-world datasets.\n",
        "- **Built-in Accessibility**: Available in popular Python libraries like `seaborn`, making it easy to use without external downloads.\n",
        "\n",
        "The Titanic dataset effectively demonstrates data cleaning techniques while being straightforward to understand and visualize.\n"
      ],
      "metadata": {
        "id": "_L5D_JXgtAPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Titanic Dataset\n",
        "\n",
        "We can load the Titanic dataset using `seaborn` or directly download it from online repositories.\n"
      ],
      "metadata": {
        "id": "BYvwd8BctHth"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q9ETSVuMAbB2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset\n",
        "titanic = sns.load_dataset('titanic')\n",
        "print(titanic.head())"
      ],
      "metadata": {
        "id": "k6umH9b_tGJc",
        "outputId": "069fbfbc-566e-4063-9478-8727eb8b7726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Handling Missing Values\n",
        "The Titanic dataset contains missing values in columns like `age`, `embark_town`, and `deck`.\n"
      ],
      "metadata": {
        "id": "dIBbOTmqtQoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(titanic.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "jox8yxYGtMFw",
        "outputId": "1c2c8b90-38f1-490d-ef0d-219a7327317f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survived         0\n",
            "pclass           0\n",
            "sex              0\n",
            "age              0\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         2\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           688\n",
            "embark_town      2\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing numerical values with the median\n",
        "titanic['age'] = titanic['age'].fillna(titanic['age'].median())\n"
      ],
      "metadata": {
        "id": "PYmYbMMMtTvR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing categorical values with the most frequent value\n",
        "titanic['embark_town'] = titanic['embark_town'].fillna(titanic['embark_town'].mode()[0])\n"
      ],
      "metadata": {
        "id": "a9GTY3XWtcFB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with a high percentage of missing values (e.g., deck)\n",
        "titanic = titanic.drop(columns=['deck'])"
      ],
      "metadata": {
        "id": "BlpHPsWRteNy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(titanic.isnull().sum())"
      ],
      "metadata": {
        "id": "cGTUB8-4tgVv",
        "outputId": "59fd2726-88a4-46c9-9924-bfb2985a5fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survived       0\n",
            "pclass         0\n",
            "sex            0\n",
            "age            0\n",
            "sibsp          0\n",
            "parch          0\n",
            "fare           0\n",
            "embarked       2\n",
            "class          0\n",
            "who            0\n",
            "adult_male     0\n",
            "embark_town    0\n",
            "alive          0\n",
            "alone          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. Outlier Detection and Removal\n",
        "We can identify outliers in numerical columns like `fare` using the interquartile range (IQR) method.\n"
      ],
      "metadata": {
        "id": "ssLf-eSVtoNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect and remove outliers using IQR\n",
        "Q1 = titanic['fare'].quantile(0.25)\n",
        "Q3 = titanic['fare'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "titanic = titanic[~((titanic['fare'] < (Q1 - 1.5 * IQR)) | (titanic['fare'] > (Q3 + 1.5 * IQR)))]\n"
      ],
      "metadata": {
        "id": "f8AI4BD1tigo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Removing Duplicates\n",
        "Duplicate rows can occur due to errors in data collection.\n"
      ],
      "metadata": {
        "id": "lXY5AroZuBcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows\n",
        "titanic = titanic.drop_duplicates()"
      ],
      "metadata": {
        "id": "34ACnE2Otsy6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 4. Standardizing Formats\n",
        "Inconsistent formats can lead to errors during analysis. For example, `embark_town` entries should be consistent.\n"
      ],
      "metadata": {
        "id": "c6uYaot3uktd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize categorical values\n",
        "titanic['embark_town'] = titanic['embark_town'].replace({'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown'})"
      ],
      "metadata": {
        "id": "Fs-E8bxYuY0x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPzbqC0Bum8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 5. Handling Inconsistent Data Entries\n",
        "Columns like `embark_town` might have inconsistent abbreviations or spellings.\n"
      ],
      "metadata": {
        "id": "pTL7JOY8u0gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace inconsistent abbreviations with full names\n",
        "titanic['embark_town'] = titanic['embark_town'].replace({'S': 'Southampton', 'C': 'Cherbourg', 'Q': 'Queenstown'})\n"
      ],
      "metadata": {
        "id": "mXM1g8sEu27D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exAhOx5bu3Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 6. Removing Irrelevant Features\n",
        "Not all features are useful for analysis. For example, `name` might not contribute to the survival prediction.\n"
      ],
      "metadata": {
        "id": "Me9UFbE0u5cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant columns\n",
        "titanic = titanic.drop(columns=['ticket'])"
      ],
      "metadata": {
        "id": "9AEYxErxu8MM",
        "outputId": "fa2dac1e-ccfe-4530-e2b2-6f0b492a4755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['ticket'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fd8f2a9aeba4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove irrelevant columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtitanic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticket'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['ticket'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cleaned Dataset\n",
        "\n",
        "After applying these techniques, the dataset is now clean and ready for analysis.\n"
      ],
      "metadata": {
        "id": "OvJ-c22AvDLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the cleaned dataset\n",
        "print(titanic.head())\n",
        "print(titanic.info())"
      ],
      "metadata": {
        "id": "TlTCpYPdu8ed",
        "outputId": "84eaa93c-5ab6-489d-df04-5ff4f18c1707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "5         0       3    male  28.0      0      0   8.4583        Q  Third   \n",
            "\n",
            "     who  adult_male  embark_town alive  alone  \n",
            "0    man        True  Southampton    no  False  \n",
            "2  woman       False  Southampton   yes   True  \n",
            "3  woman       False  Southampton   yes  False  \n",
            "4    man        True  Southampton    no   True  \n",
            "5    man        True   Queenstown    no   True  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 665 entries, 0 to 890\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   survived     665 non-null    int64   \n",
            " 1   pclass       665 non-null    int64   \n",
            " 2   sex          665 non-null    object  \n",
            " 3   age          665 non-null    float64 \n",
            " 4   sibsp        665 non-null    int64   \n",
            " 5   parch        665 non-null    int64   \n",
            " 6   fare         665 non-null    float64 \n",
            " 7   embarked     665 non-null    object  \n",
            " 8   class        665 non-null    category\n",
            " 9   who          665 non-null    object  \n",
            " 10  adult_male   665 non-null    bool    \n",
            " 11  embark_town  665 non-null    object  \n",
            " 12  alive        665 non-null    object  \n",
            " 13  alone        665 non-null    bool    \n",
            "dtypes: bool(2), category(1), float64(2), int64(4), object(5)\n",
            "memory usage: 64.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMEOZF2wvFCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}