{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCa5VbvbbVTHxE1wY1T5p2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calmrocks/master-machine-learning-engineer/blob/main/basic_models/AnomalyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro-section"
      },
      "source": [
        "# Credit Card Fraud Detection\n",
        "\n",
        "## Introduction\n",
        "This notebook demonstrates the application of machine learning for credit card fraud detection. We'll address the challenges of highly imbalanced data and the need for high precision and recall.\n",
        "\n",
        "## Dataset Overview\n",
        "- Features: V1-V28 (PCA transformed), Time, Amount\n",
        "- Target: Class (1: Fraud, 0: Normal)\n",
        "- Total Transactions: 284,807\n",
        "- Fraud Cases: 492 (0.172%)\n",
        "- Highly imbalanced dataset\n",
        "\n",
        "## Problem Statement\n",
        "1. Identify fraudulent transactions\n",
        "2. Minimize false positives\n",
        "3. Maximize fraud detection rate\n",
        "4. Handle class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-section"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn')\n",
        "sns.set_theme()\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-loading-section"
      },
      "source": [
        "## Data Loading and Exploration\n",
        "\n",
        "In this section, we'll:\n",
        "1. Load and examine the dataset\n",
        "2. Analyze class distribution\n",
        "3. Explore feature characteristics\n",
        "4. Investigate time and amount distributions\n",
        "5. Check for data quality issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-data"
      },
      "outputs": [],
      "source": [
        "# Load the credit card fraud dataset\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "\n",
        "# Display basic information\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# Check data types and missing values\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "class-distribution-section"
      },
      "source": [
        "### Class Distribution Analysis\n",
        "\n",
        "Let's examine the distribution of fraudulent vs. normal transactions and understand the extent of class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "class-distribution"
      },
      "outputs": [],
      "source": [
        "# Analyze class distribution\n",
        "class_dist = df['Class'].value_counts(normalize=True)\n",
        "print(\"Class Distribution:\")\n",
        "print(class_dist)\n",
        "\n",
        "# Visualize class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Class')\n",
        "plt.title('Class Distribution (0: Normal, 1: Fraud)')\n",
        "plt.xlabel('Transaction Class')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Add percentage labels\n",
        "total = len(df['Class'])\n",
        "for p in plt.gca().patches:\n",
        "    percentage = f'{100 * p.get_height()/total:.2f}%'\n",
        "    plt.annotate(percentage, (p.get_x() + p.get_width()/2., p.get_height()),\n",
        "                 ha='center', va='bottom')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(\"\\nDetailed Class Statistics:\")\n",
        "print(f\"Total Transactions: {len(df)}\")\n",
        "print(f\"Normal Transactions: {len(df[df['Class'] == 0])}\")\n",
        "print(f\"Fraudulent Transactions: {len(df[df['Class'] == 1])}\")\n",
        "print(f\"Fraud Ratio: 1:{len(df[df['Class'] == 0])/len(df[df['Class'] == 1]):.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "time-amount-section"
      },
      "source": [
        "### Time and Amount Analysis\n",
        "\n",
        "Examine the distribution of transaction times and amounts, which are the only non-PCA transformed features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "time-amount-analysis"
      },
      "outputs": [],
      "source": [
        "# Time analysis\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Distribution of transactions over time\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['Time'], bins=50)\n",
        "plt.title('Distribution of Transactions Over Time')\n",
        "plt.xlabel('Time (seconds)')\n",
        "plt.ylabel('Number of Transactions')\n",
        "\n",
        "# Time distribution by class\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='Class', y='Time', data=df)\n",
        "plt.title('Transaction Time by Class')\n",
        "plt.xlabel('Class (0: Normal, 1: Fraud)')\n",
        "plt.ylabel('Time (seconds)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Amount analysis\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Distribution of transaction amounts\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['Amount'], bins=50)\n",
        "plt.title('Distribution of Transaction Amounts')\n",
        "plt.xlabel('Amount')\n",
        "plt.ylabel('Number of Transactions')\n",
        "\n",
        "# Amount distribution by class\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='Class', y='Amount', data=df)\n",
        "plt.title('Transaction Amount by Class')\n",
        "plt.xlabel('Class (0: Normal, 1: Fraud)')\n",
        "plt.ylabel('Amount')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print amount statistics by class\n",
        "print(\"\\nAmount Statistics by Class:\")\n",
        "print(df.groupby('Class')['Amount'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature-analysis-section"
      },
      "source": [
        "### Feature Analysis\n",
        "\n",
        "Analyze the PCA-transformed features (V1-V28) to understand their characteristics and relationships with fraud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature-analysis"
      },
      "outputs": [],
      "source": [
        "# Select V features\n",
        "v_features = [col for col in df.columns if col.startswith('V')]\n",
        "\n",
        "# Calculate correlation with Class\n",
        "correlations = df[v_features + ['Class']].corr()['Class'].sort_values()\n",
        "print(\"Top correlations with Class:\")\n",
        "print(\"\\nMost negative correlations:\")\n",
        "print(correlations.head())\n",
        "print(\"\\nMost positive correlations:\")\n",
        "print(correlations.tail())\n",
        "\n",
        "# Visualize top correlated features\n",
        "plt.figure(figsize=(15, 5))\n",
        "top_features = list(correlations.head(3).index) + list(correlations.tail(3).index)\n",
        "\n",
        "for i, feature in enumerate(top_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.boxplot(x='Class', y=feature, data=df)\n",
        "    plt.title(f'{feature} by Class')\n",
        "    plt.xlabel('Class (0: Normal, 1: Fraud)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature-distributions-section"
      },
      "source": [
        "### Feature Distributions\n",
        "\n",
        "Examine the distributions of key features for normal and fraudulent transactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature-distributions"
      },
      "outputs": [],
      "source": [
        "# Select top correlated features for detailed analysis\n",
        "top_corr_features = top_features[:6]\n",
        "\n",
        "# Create KDE plots\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(top_corr_features, 1):\n",
        "    plt.subplot(2, 3, i)\n",
        "    sns.kdeplot(data=df[df['Class']==0][feature], label='Normal', shade=True)\n",
        "    sns.kdeplot(data=df[df['Class']==1][feature], label='Fraud', shade=True)\n",
        "    plt.title(f'{feature} Distribution by Class')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "initial-findings"
      },
      "source": [
        "### Initial Findings\n",
        "\n",
        "1. **Class Imbalance**:\n",
        "   - Extreme imbalance (0.172% fraud cases)\n",
        "   - Need for special handling in modeling\n",
        "   - Importance of appropriate evaluation metrics\n",
        "\n",
        "2. **Time and Amount**:\n",
        "   - Transactions spread over ~2 days\n",
        "   - Amount distributions differ between classes\n",
        "   - Potential for feature engineering\n",
        "\n",
        "3. **PCA Features**:\n",
        "   - Several features show strong correlation with fraud\n",
        "   - Clear separation between classes in some features\n",
        "   - Potential for effective fraud detection\n",
        "\n",
        "4. **Data Quality**:\n",
        "   - No missing values\n",
        "   - All features properly scaled (except Time and Amount)\n",
        "   - Clean dataset ready for modeling\n",
        "\n",
        "Next steps:\n",
        "1. Feature engineering (especially for Time and Amount)\n",
        "2. Proper scaling of all features\n",
        "3. Implementation of class imbalance handling techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature-engineering-section"
      },
      "source": [
        "## Feature Engineering and Preprocessing\n",
        "\n",
        "We'll prepare our data through:\n",
        "1. Feature engineering for Time and Amount\n",
        "2. Feature scaling and normalization\n",
        "3. Feature selection based on importance\n",
        "4. Data splitting with stratification\n",
        "\n",
        "Given the nature of fraud detection, we'll focus on creating meaningful features while preserving the ability to detect anomalies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "time-engineering-section"
      },
      "source": [
        "### Time Feature Engineering\n",
        "\n",
        "Transform the Time feature to extract meaningful patterns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "time-engineering"
      },
      "outputs": [],
      "source": [
        "# Convert time to hours and extract cyclical features\n",
        "df['Hour'] = df['Time'] / 3600  # Convert seconds to hours\n",
        "\n",
        "# Create cyclical time features\n",
        "df['Hour_sin'] = np.sin(2 * np.pi * df['Hour']/24.0)\n",
        "df['Hour_cos'] = np.cos(2 * np.pi * df['Hour']/24.0)\n",
        "\n",
        "# Create time windows for transaction density\n",
        "window_size = 3600  # 1 hour window\n",
        "df['Trans_density'] = df['Time'].rolling(window=window_size).count()\n",
        "df['Trans_density'].fillna(df['Trans_density'].mean(), inplace=True)\n",
        "\n",
        "# Visualize new time features\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot cyclical features\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(df['Hour_sin'], df['Hour_cos'], c=df['Class'], \n",
        "            alpha=0.5, cmap='coolwarm')\n",
        "plt.title('Cyclical Time Features')\n",
        "plt.xlabel('Hour_sin')\n",
        "plt.ylabel('Hour_cos')\n",
        "\n",
        "# Plot transaction density\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x='Class', y='Trans_density', data=df)\n",
        "plt.title('Transaction Density by Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amount-engineering-section"
      },
      "source": [
        "### Amount Feature Engineering\n",
        "\n",
        "Create features based on transaction amounts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amount-engineering"
      },
      "outputs": [],
      "source": [
        "# Log transform amount\n",
        "df['Amount_log'] = np.log1p(df['Amount'])\n",
        "\n",
        "# Calculate amount statistics in time windows\n",
        "df['Amount_mean_window'] = df['Amount'].rolling(window=window_size).mean()\n",
        "df['Amount_std_window'] = df['Amount'].rolling(window=window_size).std()\n",
        "\n",
        "# Calculate z-score of amount\n",
        "df['Amount_zscore'] = (df['Amount'] - df['Amount_mean_window']) / df['Amount_std_window']\n",
        "\n",
        "# Fill NaN values with means\n",
        "amount_features = ['Amount_mean_window', 'Amount_std_window', 'Amount_zscore']\n",
        "for feature in amount_features:\n",
        "    df[feature].fillna(df[feature].mean(), inplace=True)\n",
        "\n",
        "# Visualize new amount features\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot amount log distribution\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.boxplot(x='Class', y='Amount_log', data=df)\n",
        "plt.title('Log Amount by Class')\n",
        "\n",
        "# Plot amount z-score\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.boxplot(x='Class', y='Amount_zscore', data=df)\n",
        "plt.title('Amount Z-score by Class')\n",
        "\n",
        "# Plot amount statistics\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.scatterplot(data=df, x='Amount_mean_window', y='Amount_std_window',\n",
        "                hue='Class', alpha=0.5)\n",
        "plt.title('Amount Statistics Window')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interaction-features-section"
      },
      "source": [
        "### Feature Interactions\n",
        "\n",
        "Create interaction features between important V features:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interaction-features"
      },
      "outputs": [],
      "source": [
        "# Get top correlated V features\n",
        "top_v_features = correlations.abs().sort_values(ascending=False)[1:4].index\n",
        "\n",
        "# Create interaction features\n",
        "for i in range(len(top_v_features)):\n",
        "    for j in range(i+1, len(top_v_features)):\n",
        "        feat1, feat2 = top_v_features[i], top_v_features[j]\n",
        "        df[f'{feat1}_{feat2}_mult'] = df[feat1] * df[feat2]\n",
        "        df[f'{feat1}_{feat2}_diff'] = df[feat1] - df[feat2]\n",
        "\n",
        "# Analyze new interaction features\n",
        "interaction_features = [col for col in df.columns if '_mult' in col or '_diff' in col]\n",
        "\n",
        "# Plot distributions of interaction features\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, feature in enumerate(interaction_features[:3], 1):\n",
        "    plt.subplot(1, 3, i)\n",
        "    sns.boxplot(x='Class', y=feature, data=df)\n",
        "    plt.title(f'{feature} by Class')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature-selection-section"
      },
      "source": [
        "### Feature Selection and Scaling\n",
        "\n",
        "Select and scale features for modeling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature-selection"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# Prepare feature set\n",
        "feature_columns = (\n",
        "    v_features +  # Original V features\n",
        "    ['Hour_sin', 'Hour_cos', 'Trans_density'] +  # Time features\n",
        "    ['Amount_log', 'Amount_zscore', 'Amount_mean_window', 'Amount_std_window'] +  # Amount features\n",
        "    interaction_features  # Interaction features\n",
        ")\n",
        "\n",
        "# Select features using ANOVA F-value\n",
        "selector = SelectKBest(f_classif, k=30)  # Select top 30 features\n",
        "X = df[feature_columns]\n",
        "y = df['Class']\n",
        "\n",
        "# Fit selector\n",
        "selector.fit(X, y)\n",
        "selected_features_mask = selector.get_support()\n",
        "selected_features = X.columns[selected_features_mask].tolist()\n",
        "\n",
        "# Create final feature matrix\n",
        "X_selected = df[selected_features]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=selected_features)\n",
        "\n",
        "# Display selected features and their scores\n",
        "feature_scores = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Score': selector.scores_[selected_features_mask]\n",
        "}).sort_values('Score', ascending=False)\n",
        "\n",
        "print(\"Top 10 Selected Features:\")\n",
        "display(feature_scores.head(10))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Score', y='Feature', data=feature_scores.head(10))\n",
        "plt.title('Top 10 Features by F-score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-test-split-section"
      },
      "source": [
        "### Train-Test Split\n",
        "\n",
        "Split the data while preserving class distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train-test-split"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Print split sizes\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n",
        "\n",
        "# Verify class distribution in splits\n",
        "print(\"\\nClass distribution in training set:\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nClass distribution in testing set:\")\n",
        "print(y_test.value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing-summary"
      },
      "source": [
        "### Feature Engineering Summary\n",
        "\n",
        "1. **Time Features**:\n",
        "   - Converted to cyclical representation\n",
        "   - Added transaction density\n",
        "   - Captured temporal patterns\n",
        "\n",
        "2. **Amount Features**:\n",
        "   - Log transformation\n",
        "   - Rolling statistics\n",
        "   - Z-score normalization\n",
        "\n",
        "3. **Interaction Features**:\n",
        "   - Created from top correlated features\n",
        "   - Captured feature relationships\n",
        "   - Enhanced predictive power\n",
        "\n",
        "4. **Feature Selection**:\n",
        "   - Selected top 30 features\n",
        "   - Used ANOVA F-scores\n",
        "   - Balanced original and engineered features\n",
        "\n",
        "Next steps:\n",
        "1. Model implementation\n",
        "2. Class imbalance handling\n",
        "3. Model evaluation with focus on fraud detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-implementation-section"
      },
      "source": [
        "## Model Implementation\n",
        "\n",
        "We'll implement several models suitable for fraud detection:\n",
        "1. Logistic Regression (baseline)\n",
        "2. Random Forest\n",
        "3. XGBoost\n",
        "4. LightGBM\n",
        "\n",
        "For each model, we'll:\n",
        "- Initialize with class weights\n",
        "- Train with appropriate parameters\n",
        "- Evaluate with fraud-detection metrics\n",
        "- Analyze prediction probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model-utils"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, roc_curve, auc\n",
        "\n",
        "def evaluate_fraud_model(y_true, y_pred, y_prob, model_name):\n",
        "    \"\"\"Evaluate model with fraud-specific metrics.\"\"\"\n",
        "    \n",
        "    # Calculate metrics\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cr = classification_report(y_true, y_pred)\n",
        "    \n",
        "    # Calculate ROC and PR curves\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "    \n",
        "    # Plot results\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    sns.heatmap(cm, annot=True, fmt='d', ax=ax1)\n",
        "    ax1.set_title(f'{model_name} Confusion Matrix')\n",
        "    ax1.set_xlabel('Predicted')\n",
        "    ax1.set_ylabel('Actual')\n",
        "    \n",
        "    # ROC Curve\n",
        "    ax2.plot(fpr, tpr, label=f'ROC curve (AUC = {auc(fpr, tpr):.3f})')\n",
        "    ax2.plot([0, 1], [0, 1], 'k--')\n",
        "    ax2.set_title(f'{model_name} ROC Curve')\n",
        "    ax2.set_xlabel('False Positive Rate')\n",
        "    ax2.set_ylabel('True Positive Rate')\n",
        "    ax2.legend()\n",
        "    \n",
        "    # Precision-Recall Curve\n",
        "    ax3.plot(recall, precision)\n",
        "    ax3.set_title(f'{model_name} Precision-Recall Curve')\n",
        "    ax3.set_xlabel('Recall')\n",
        "    ax3.set_ylabel('Precision')\n",
        "    \n",
        "    # Probability Distribution\n",
        "    sns.histplot(data=pd.DataFrame({\n",
        "        'Probability': y_prob,\n",
        "        'Class': y_true\n",
        "    }), x='Probability', hue='Class', bins=50, ax=ax4)\n",
        "    ax4.set_title(f'{model_name} Probability Distribution')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\n{model_name} Classification Report:\")\n",
        "    print(cr)\n",
        "    \n",
        "    return {\n",
        "        'confusion_matrix': cm,\n",
        "        'classification_report': cr,\n",
        "        'roc_auc': auc(fpr, tpr)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "logistic-regression-section"
      },
      "source": [
        "### Logistic Regression (Baseline Model)\n",
        "\n",
        "Implement a baseline model with class weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "logistic-regression"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize and train logistic regression\n",
        "lr_model = LogisticRegression(\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "lr_prob = lr_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "lr_results = evaluate_fraud_model(y_test, lr_pred, lr_prob, 'Logistic Regression')\n",
        "\n",
        "# Feature importance\n",
        "lr_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': abs(lr_model.coef_[0])\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=lr_importance.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Features (Logistic Regression)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "random-forest-section"
      },
      "source": [
        "### Random Forest\n",
        "\n",
        "Implement Random Forest with balanced class weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "random-forest"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and train Random Forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=10,\n",
        "    min_samples_split=10,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "rf_prob = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "rf_results = evaluate_fraud_model(y_test, rf_pred, rf_prob, 'Random Forest')\n",
        "\n",
        "# Feature importance\n",
        "rf_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=rf_importance.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Features (Random Forest)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgboost-section"
      },
      "source": [
        "### XGBoost\n",
        "\n",
        "Implement XGBoost with scale_pos_weight for imbalance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgboost"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Calculate scale_pos_weight\n",
        "scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
        "\n",
        "# Initialize and train XGBoost\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "xgb_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "xgb_results = evaluate_fraud_model(y_test, xgb_pred, xgb_prob, 'XGBoost')\n",
        "\n",
        "# Feature importance\n",
        "xgb_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': xgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=xgb_importance.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Features (XGBoost)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lightgbm-section"
      },
      "source": [
        "### LightGBM\n",
        "\n",
        "Implement LightGBM with built-in class weights:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lightgbm"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Initialize and train LightGBM\n",
        "lgb_model = LGBMClassifier(\n",
        "    n_estimators=200,\n",
        "    num_leaves=31,\n",
        "    learning_rate=0.1,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "lgb_pred = lgb_model.predict(X_test)\n",
        "lgb_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate model\n",
        "lgb_results = evaluate_fraud_model(y_test, lgb_pred, lgb_prob, 'LightGBM')\n",
        "\n",
        "# Feature importance\n",
        "lgb_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': lgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=lgb_importance.head(10), x='importance', y='feature')\n",
        "plt.title('Top 10 Features (LightGBM)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-comparison-section"
      },
      "source": [
        "### Model Comparison\n",
        "\n",
        "Compare all models' performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model-comparison"
      },
      "outputs": [],
      "source": [
        "# Collect all results\n",
        "models = {\n",
        "    'Logistic Regression': (lr_pred, lr_prob),\n",
        "    'Random Forest': (rf_pred, rf_prob),\n",
        "    'XGBoost': (xgb_pred, xgb_prob),\n",
        "    'LightGBM': (lgb_pred, lgb_prob)\n",
        "}\n",
        "\n",
        "# Compare ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "for name, (_, y_prob) in models.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc(fpr, tpr):.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Compare metrics\n",
        "results = []\n",
        "for name, (y_pred, y_prob) in models.items():\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1': f1_score(y_test, y_pred),\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_prob)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Model Performance Comparison:\")\n",
        "display(results_df.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "implementation-summary"
      },
      "source": [
        "### Model Implementation Summary\n",
        "\n",
        "1. **Model Performance**:\n",
        "   - Best performing model: [based on results]\n",
        "   - Trade-offs between precision and recall\n",
        "   - ROC-AUC scores comparison\n",
        "\n",
        "2. **Feature Importance**:\n",
        "   - Consistent important features across models\n",
        "   - Engineered features effectiveness\n",
        "   - Model-specific feature rankings\n",
        "\n",
        "3. **Practical Considerations**:\n",
        "   - Model complexity vs. performance\n",
        "   - Training time requirements\n",
        "   - Prediction speed needs\n",
        "\n",
        "Next steps:\n",
        "1. Hyperparameter tuning\n",
        "2. Ensemble methods\n",
        "3. Threshold optimization\n",
        "4. Model deployment preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbalance-section"
      },
      "source": [
        "## Handling Class Imbalance\n",
        "\n",
        "We'll address the severe class imbalance (0.172% fraud) using multiple techniques:\n",
        "1. Resampling methods (SMOTE, ADASYN)\n",
        "2. Undersampling techniques\n",
        "3. Combination approaches\n",
        "4. Cost-sensitive learning\n",
        "\n",
        "We'll evaluate each approach using our best performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "resampling-imports"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "from collections import Counter\n",
        "\n",
        "def plot_class_distribution(y, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(x=y)\n",
        "    plt.title(f'Class Distribution - {title}')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Count')\n",
        "    \n",
        "    # Add percentage labels\n",
        "    total = len(y)\n",
        "    for p in plt.gca().patches:\n",
        "        percentage = f'{100 * p.get_height()/total:.2f}%'\n",
        "        plt.annotate(percentage, (p.get_x() + p.get_width()/2., p.get_height()),\n",
        "                     ha='center', va='bottom')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nClass distribution in {title}:\")\n",
        "    print(pd.Series(y).value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smote-section"
      },
      "source": [
        "### SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "\n",
        "Apply SMOTE to create synthetic samples of the minority class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smote-implementation"
      },
      "outputs": [],
      "source": [
        "# Apply SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Plot new distribution\n",
        "plot_class_distribution(y_train_smote, 'SMOTE')\n",
        "\n",
        "# Train model on SMOTE-balanced data\n",
        "best_model_smote = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model_smote.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Evaluate\n",
        "smote_pred = best_model_smote.predict(X_test)\n",
        "smote_prob = best_model_smote.predict_proba(X_test)[:, 1]\n",
        "\n",
        "smote_results = evaluate_fraud_model(y_test, smote_pred, smote_prob, 'SMOTE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adasyn-section"
      },
      "source": [
        "### ADASYN (Adaptive Synthetic Sampling)\n",
        "\n",
        "Apply ADASYN to generate synthetic samples based on density distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adasyn-implementation"
      },
      "outputs": [],
      "source": [
        "# Apply ADASYN\n",
        "adasyn = ADASYN(sampling_strategy='auto', random_state=42)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Plot new distribution\n",
        "plot_class_distribution(y_train_adasyn, 'ADASYN')\n",
        "\n",
        "# Train model on ADASYN-balanced data\n",
        "best_model_adasyn = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
        "\n",
        "# Evaluate\n",
        "adasyn_pred = best_model_adasyn.predict(X_test)\n",
        "adasyn_prob = best_model_adasyn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "adasyn_results = evaluate_fraud_model(y_test, adasyn_pred, adasyn_prob, 'ADASYN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "combination-section"
      },
      "source": [
        "### Combination Approaches\n",
        "\n",
        "Apply SMOTE with Tomek links and SMOTE with ENN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "combination-implementation"
      },
      "outputs": [],
      "source": [
        "# SMOTE + Tomek links\n",
        "smote_tomek = SMOTETomek(random_state=42)\n",
        "X_train_smt, y_train_smt = smote_tomek.fit_resample(X_train, y_train)\n",
        "\n",
        "# SMOTE + ENN\n",
        "smote_enn = SMOTEENN(random_state=42)\n",
        "X_train_smenn, y_train_smenn = smote_enn.fit_resample(X_train, y_train)\n",
        "\n",
        "# Plot distributions\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_class_distribution(y_train_smt, 'SMOTE + Tomek')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_class_distribution(y_train_smenn, 'SMOTE + ENN')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Train and evaluate models\n",
        "# SMOTE + Tomek\n",
        "best_model_smt = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model_smt.fit(X_train_smt, y_train_smt)\n",
        "smt_pred = best_model_smt.predict(X_test)\n",
        "smt_prob = best_model_smt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "smt_results = evaluate_fraud_model(y_test, smt_pred, smt_prob, 'SMOTE + Tomek')\n",
        "\n",
        "# SMOTE + ENN\n",
        "best_model_smenn = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model_smenn.fit(X_train_smenn, y_train_smenn)\n",
        "smenn_pred = best_model_smenn.predict(X_test)\n",
        "smenn_prob = best_model_smenn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "smenn_results = evaluate_fraud_model(y_test, smenn_pred, smenn_prob, 'SMOTE + ENN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "undersampling-section"
      },
      "source": [
        "### Random Undersampling\n",
        "\n",
        "Apply random undersampling to balance classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "undersampling-implementation"
      },
      "outputs": [],
      "source": [
        "# Apply random undersampling\n",
        "rus = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Plot new distribution\n",
        "plot_class_distribution(y_train_rus, 'Random Undersampling')\n",
        "\n",
        "# Train model on undersampled data\n",
        "best_model_rus = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "best_model_rus.fit(X_train_rus, y_train_rus)\n",
        "\n",
        "# Evaluate\n",
        "rus_pred = best_model_rus.predict(X_test)\n",
        "rus_prob = best_model_rus.predict_proba(X_test)[:, 1]\n",
        "\n",
        "rus_results = evaluate_fraud_model(y_test, rus_pred, rus_prob, 'Random Undersampling')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparison-section"
      },
      "source": [
        "### Comparison of Resampling Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "resampling-comparison"
      },
      "outputs": [],
      "source": [
        "# Collect all results\n",
        "resampling_results = {\n",
        "    'Original': (xgb_pred, xgb_prob),\n",
        "    'SMOTE': (smote_pred, smote_prob),\n",
        "    'ADASYN': (adasyn_pred, adasyn_prob),\n",
        "    'SMOTE + Tomek': (smt_pred, smt_prob),\n",
        "    'SMOTE + ENN': (smenn_pred, smenn_prob),\n",
        "    'Random Undersampling': (rus_pred, rus_prob)\n",
        "}\n",
        "\n",
        "# Compare ROC curves\n",
        "plt.figure(figsize=(12, 8))\n",
        "for name, (_, y_prob) in resampling_results.items():\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc(fpr, tpr):.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves - Resampling Techniques Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Compare metrics\n",
        "results = []\n",
        "for name, (y_pred, y_prob) in resampling_results.items():\n",
        "    results.append({\n",
        "        'Method': name,\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1': f1_score(y_test, y_pred),\n",
        "        'ROC-AUC': roc_auc_score(y_test, y_prob)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Resampling Methods Comparison:\")\n",
        "display(results_df.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbalance-summary"
      },
      "source": [
        "### Class Imbalance Handling Summary\n",
        "\n",
        "1. **Resampling Effects**:\n",
        "   - Impact on model performance\n",
        "   - Trade-offs between different techniques\n",
        "   - Best approach for fraud detection\n",
        "\n",
        "2. **Method Comparison**:\n",
        "   - SMOTE vs ADASYN effectiveness\n",
        "   - Combination methods benefits\n",
        "   - Undersampling considerations\n",
        "\n",
        "3. **Practical Implications**:\n",
        "   - Model stability\n",
        "   - Computational requirements\n",
        "   - Real-world applicability\n",
        "\n",
        "4. **Recommendations**:\n",
        "   - Best method for production\n",
        "   - Implementation considerations\n",
        "   - Monitoring requirements\n",
        "\n",
        "Next steps:\n",
        "1. Fine-tune best performing approach\n",
        "2. Implement ensemble with different sampling methods\n",
        "3. Develop monitoring strategy for production"
      ]
    }
  ]
}