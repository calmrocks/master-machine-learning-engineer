{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "title": "Building an Image Classification Model with Transfer Learning",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calmrocks/master-machine-learning-engineer/blob/main/BasicModels/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_mja3IzOtpO"
      },
      "source": [
        "## Case Study: Building an Image Classification Model with Transfer Learning\n",
        "\n",
        "This case study demonstrates how to develop an image classification model using transfer learning on the **CIFAR-10 Dataset**. We explore preprocessing techniques, feature extraction, and transfer learning with a pretrained model to classify images into ten categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRjOjhedOtpP"
      },
      "source": [
        "### Dataset Overview\n",
        "\n",
        "The **CIFAR-10 Dataset** is a widely used benchmark for image classification tasks. It contains:\n",
        "- **Images**: 60,000 color images, each 32x32 pixels.\n",
        "- **Classes**: 10 categories such as airplanes, automobiles, birds, cats, and dogs.\n",
        "- **Split**: 50,000 training images and 10,000 test images.\n",
        "\n",
        "The dataset is available through the [CIFAR-10 website](https://www.cs.toronto.edu/~kriz/cifar.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx14hN6JOtpP"
      },
      "source": [
        "## Step 1: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa-EHsRQOtpP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Display a few sample images\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.title(class_names[y_train[i][0]])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tocUwLckOtpP"
      },
      "source": [
        "### Preprocessing Steps:\n",
        "1. **Normalization**: Scale pixel values to the range [0, 1] to stabilize training.\n",
        "2. **One-Hot Encoding**: Convert class labels into one-hot vectors for compatibility with classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbVgcaE5OtpQ"
      },
      "source": [
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYe4xzRqOtpQ"
      },
      "source": [
        "## Step 2: Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXhenYvOtpQ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define augmentation transformations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "# Apply augmentation\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1yqHfTTOtpQ"
      },
      "source": [
        "## Step 3: Transfer Learning with Pretrained Models\n",
        "\n",
        "Using a pretrained model such as ResNet50 allows leveraging learned features from large-scale datasets like ImageNet, reducing training time and improving performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTJBHQfhOtpR"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the pretrained ResNet50 model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2eYuxXGOtpR"
      },
      "source": [
        "## Step 4: Model Evaluation and Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU1BtoeZOtpR"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwM0qi0rOtpR"
      },
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ-eDqrbOtpR"
      },
      "source": [
        "## Step 5: Deployment and Applications\n",
        "\n",
        "### Deployment Options:\n",
        "- **Batch Inference**: Use the model for batch predictions on datasets, such as categorizing large image collections.\n",
        "- **Real-Time Classification**: Deploy the model on a web application or mobile app for live image recognition.\n",
        "\n",
        "### Applications:\n",
        "1. **E-Commerce**: Automatically categorize product images for streamlined inventory management.\n",
        "2. **Healthcare**: Classify medical images to aid diagnostics, such as detecting diseases in X-rays.\n",
        "3. **Autonomous Vehicles**: Recognize objects like pedestrians and traffic signs in real-time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9xJOtKFOtpS"
      },
      "source": [
        "## Summary and Recommendations\n",
        "\n",
        "### Summary:\n",
        "- **Preprocessing**: Normalization and augmentation improve model robustness and performance.\n",
        "- **Transfer Learning**: Pretrained models like ResNet50 reduce training time and achieve higher accuracy with smaller datasets.\n",
        "- **Evaluation and Optimization**: Monitoring training and validation performance ensures the model generalizes well.\n",
        "\n",
        "### Recommendations:\n",
        "- Use **data augmentation** to artificially expand training datasets, especially when data is limited.\n",
        "- Apply **transfer learning** to leverage powerful pretrained models for small or medium-sized datasets.\n",
        "- Continuously monitor performance metrics during training to detect overfitting or underfitting.\n",
        "\n",
        "By following these steps, practitioners can build robust image classification models that generalize well to real-world applications, making them suitable for deployment in diverse domains."
      ]
    }
  ]
}