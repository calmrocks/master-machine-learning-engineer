{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "title": "Forecasting Energy Demand Using Time-Series Analysis",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calmrocks/master-machine-learning-engineer/blob/main/BasicModels/TimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGGpQI4DW5Fo"
      },
      "source": [
        "## Case Study: Forecasting Energy Demand Using Time-Series Analysis\n",
        "\n",
        "In this case study, we demonstrate how to apply time-series forecasting techniques to predict energy demand using the **Electricity Load Diagrams 2011** dataset, a popular open-source dataset. We will explore the steps to prepare the data, analyze its trends and seasonality, and build a forecasting model using SARIMA and LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mqn7NT0-W5Fp"
      },
      "source": [
        "### Dataset Overview\n",
        "\n",
        "The Electricity Load Diagrams 2011 dataset contains hourly electrical load data from a Portuguese electricity provider. The data spans a full year, making it suitable for exploring trends, seasonality, and short-term variations.\n",
        "\n",
        "#### Key Features:\n",
        "- **Datetime**: The timestamp for each observation.\n",
        "- **Load (kW)**: The hourly electricity consumption.\n",
        "\n",
        "The dataset is available for download [here](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams2011)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh_-sPMFW5Fp"
      },
      "source": [
        "### Step 1: Data Preparation\n",
        "\n",
        "Before building a model, we need to load, clean, and preprocess the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeImQiY9W5Fp"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"LD2011_2011.txt\", sep=\";\", index_col=0, parse_dates=True)\n",
        "\n",
        "# Select a single household's data for simplicity\n",
        "household_data = data.iloc[:, 0]  # Selecting the first column\n",
        "household_data = household_data.resample('H').mean()  # Resample to hourly data\n",
        "\n",
        "# Plot the time series\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(household_data, label=\"Hourly Energy Consumption\")\n",
        "plt.title(\"Hourly Energy Consumption (2011)\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Energy Consumption (kW)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cGLKfv0W5Fq"
      },
      "source": [
        "### Step 2: Exploratory Data Analysis\n",
        "\n",
        "#### Decomposition of Time-Series\n",
        "Using Seasonal-Trend decomposition (STL) to separate the series into trend, seasonality, and residual components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cpzeQEWW5Fq"
      },
      "source": [
        "from statsmodels.tsa.seasonal import STL\n",
        "\n",
        "# Perform STL decomposition\n",
        "stl = STL(household_data, seasonal=24)  # 24-hour daily seasonality\n",
        "result = stl.fit()\n",
        "\n",
        "# Plot components\n",
        "result.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYxAvlMbW5Fq"
      },
      "source": [
        "### Step 3: Model Building\n",
        "\n",
        "#### A. SARIMA Model\n",
        "SARIMA (Seasonal ARIMA) is well-suited for capturing both trends and seasonality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p36lORlWW5Fr"
      },
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train = household_data[:'2011-10']\n",
        "test = household_data['2011-11':]\n",
        "\n",
        "# Fit SARIMA model\n",
        "sarima_model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 24))\n",
        "sarima_result = sarima_model.fit()\n",
        "\n",
        "# Forecast\n",
        "forecast = sarima_result.forecast(steps=len(test))\n",
        "\n",
        "# Evaluate model\n",
        "mse = mean_squared_error(test, forecast)\n",
        "print(f\"SARIMA Test MSE: {mse}\")\n",
        "\n",
        "# Plot forecast\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train, label=\"Training Data\")\n",
        "plt.plot(test, label=\"Test Data\", color=\"orange\")\n",
        "plt.plot(test.index, forecast, label=\"SARIMA Forecast\", color=\"green\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH2MTo-6W5Fr"
      },
      "source": [
        "#### B. LSTM Model\n",
        "Long Short-Term Memory (LSTM) networks handle non-linear patterns and long-term dependencies in time-series data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d2gTnksW5Fr"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Prepare data for LSTM\n",
        "def create_lagged_data(series, lag):\n",
        "    X, y = [], []\n",
        "    for i in range(len(series) - lag):\n",
        "        X.append(series[i:i+lag])\n",
        "        y.append(series[i+lag])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create lagged dataset\n",
        "lag = 24\n",
        "X, y = create_lagged_data(household_data.values, lag)\n",
        "\n",
        "# Split into train and test\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Reshape for LSTM input\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(lag, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Forecast\n",
        "lstm_forecast = model.predict(X_test)\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_test, label=\"Actual Data\", color=\"orange\")\n",
        "plt.plot(lstm_forecast, label=\"LSTM Forecast\", color=\"green\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKSrhs22W5Fr"
      },
      "source": [
        "### Step 4: Summary and Recommendations\n",
        "\n",
        "#### Summary:\n",
        "- **SARIMA**: Suitable for capturing linear trends and seasonality in time-series data.\n",
        "- **LSTM**: Effective for handling non-linear patterns and long-term dependencies.\n",
        "\n",
        "#### Recommendations:\n",
        "- For simpler time-series data with clear seasonality, SARIMA provides interpretable and robust forecasts.\n",
        "- For complex data with non-linear patterns or multiple seasonal cycles, LSTM offers better adaptability and accuracy.\n",
        "\n",
        "#### Next Steps:\n",
        "- Experiment with hybrid models combining SARIMA and LSTM to leverage their strengths.\n",
        "- Explore advanced techniques like Prophet or Transformer-based time-series models for further improvement."
      ]
    }
  ]
}